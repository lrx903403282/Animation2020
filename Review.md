# 基于神经网络的人物动作捕捉和角色动作生成文献综述
## 1 背景




## 2 里程碑

### 2.1 相位函数神经网络(PFNN)

Daniel Holden等人提出的PFNN(Phase-Functional Neural Network, 相位函数神经网络)，主要针对于虚拟角色的实时动作控制。由于这个问题有太多需求需要满足，因而这个问题还是比较具有挑战性的。而当情况更复杂时，例如环境由不平坦的地形和大的障碍物组成时，该问题甚至更具有挑战性。

在Holden的论文中，主要贡献是提供了一种基于神经网络的实时运动合成框架PFNN和为PFNN准备训练数据的过程。PFNN的工作原理是在每帧生成一个回归网络的权重，以作为相位的函数。生成以后，该权重将会作为该帧的控制参数以控制角色运动。PFNN的设计避免了明确地混合几个相位的数据，而是通过建立了一个随时间平滑演变的回归函数来实现。与不同的神经模型相比，PFNN具有以下优势：

1. 不同于CNN这样的离线模型，PFNN是在线实时运动生成的模型。
2. 不同于RNN模型，PFNN能够生成更加稳定且在与用户交互的复杂环境下更高质量的运动。
3. PFNN运行速度很快而且所需内存很小，只需要几毫秒的执行时间和几MB的内存。

同时在论文中，笔者也提出了PFNN模型的局限性。

1. 系统为了实现实时性能忽略了一些高分辨率细节，例如地形中尖锐细小的障碍物。
2. 本模型无法很好地处理对环境与地形的复杂交互，尤其是精细的手部动作，例如爬上墙壁或与其他对象交互。
3. 由于minibatch中地每个元素产生不同的权值，从而导致训练过程中计算的代价更大，所有PFNN的训练速度相对较慢。
4. 如果用户提供的输入在给定环境中无法实现（例如地形太陡），系统会产生不合需求的结果。
5. 模型结果可能会难以预测，因此难以修改或编辑。

### 2.2 模式自适应神经网络(MANN)



### 2.3 神经状态机(NSM)

基于场景理解的精确控制能够很好地帮助人物角色实现自我定位和导航，从而到达设定的目标位置。Holden等人提出了神经状态机(NSM)，一种引导角色通过精确场景交互实现目标驱动行为的框架。Holden等人在2017年提出的相位函数神经网络(PFNN)通过监督学习进行建模，生成高质量的人物动作并控制角色在有限区域内的运动。神经状态机将高质量的动作生成应用于支持人物角色与环境的交互，基于高阶的场景理解控制角色实现一系列复杂的人物动作。

神经状态机的贡献主要体现在以下几点：
1. 神经状态机构造出一种信号，将动作的相位编码成为高级动作描述标签和目标位置，通过数据集的深度学习，神经网络能够根据高级的指令生成高质量的人物角色动作。神经状态机以一种端到端的方式从数据集中分解权重，改良了传统的使用固定相位函数方法所带来的局限性，即只能应用于周期性的人物动作。
2. 神经状态机实现了一种双向控制框架，该框架综合了第一人称视角和目标视角对人物角色动作的预测，预测结果被实时地反馈给神经网络，从而产生连续的、高精确度的角色运动轨迹。
3. 神经状态机将体积表示方法应用于环境理解，改良了传统等高线表示方法所带来的局限性。该方法增强了了角色与凹形物体的交互效果，
4. 作者设计了一种增强数据集的方案，通过在数据集的每一帧中随机地切换环境变量中的几何物体，且不改变动作和交互的连贯性，使得神经网络获得更大的学习量，而不需要增大数据集的数据量。



## 3 相关工作

### 数据驱动的运动合成技术

**1.1 基于线性模型的方法**

1. 在Howe等人1999年的论文和Safonova等人2004年的论文中都提到了主成分分析(PCA)用于降低运动数据的维数并用于从较少数量的输入来预测全身运动。
2. 关于PCA的应用。Chai和Hodgins在2005年采用局部PCA来合成具有稀疏标记集的全身运动；Tautges等人在2011年利用稀疏惯性传感器产生的类似局部结构来预测全身运动。
这些采用局部或全局PCA的方法在训练和运行时需要大量的计算和预处理。

**1.2 基于内核的方法**可以用来克服线性方法的局限性并考虑数据的非线性。基于径向函数(Radial Basis Functions, RBF)和高斯过程(Gaussian Process, GP)是混合不同类型运动的常用方法。

1. Grochow等人于2004年应用了高斯过程潜在变量模型(Gaussian Process Latent Variable Models, GPLVM)来计算数据的低维度潜在空间以帮助解决反向运动的冗余问题。之后Levine等人在2012年运用GPLVM来提升计划移动的效率。
2. Wang等人于2008年提出了高斯过程动态模型(Gaussian Process Dynamic Model, GPDM),GPDM的工作原理是学习潜在空间的动力学并将动作通过另一个GP投影到整个空间中。
3. 上面这些基于内核的方法在存储和求协方差矩阵的逆矩阵时需要较高的内存成本，二者存储代价规模分别为$N^2$和$N^3$(其中N为数据点数)。Rasmussen和Ghahramani在2002年提出了局部GP方法来限制插值的样本数来解决这个问题。

**1.3 基于神经网络的方法**由于其高可扩展性和高运行效率而成为一个热点。

1. 其中一类模型是基于角色的先前运动姿态来预测角色的当前姿态，被称为自回归模型。Taylor等人于2009年提出的cRBM模型、Fragkiadaki等人于2015年提出的应用潜在空间的LSTM模型的RNN模型都属于自回归模型。这些自回归模型相较于线性方法和内核方法具有更大的规模和更高的运行效率。但是由于噪声和低拟合度的数据积累，运动会逐渐偏离运动流形，无法保证其稳定性。
2. Holden等人于2016年改为使用CNN模型，将低维用户信号映射到全身的动作中，这种算法稳定性很好但是它是一个离线框架，需要在合成运动之前指定沿时间线的完整控制信号。

### 与环境的交互的自动角色控制方法

这些控制方法可以分为两类，基于优化的方法和形状匹配。

**1.1 基于优化的方法**

1. 基于优化的方法[Lau和Kuffner于2005年，Safonova和Hodgins于2007年],基于抽样的方法[Coros等人于2008年，Liu等人于2010年],最大后验概率(MAP)估计[Chai和Hodgins于207年，Min和Chai于2012你年],强化学习方法[Lee和Lee于2004年，Lee等人于2010年，Levine等人于2012年，Lo和Zwicker于2008年，彭等人于2016年]都可以根据角色的当前状态（包括姿势）和它与环境集合的关系来预测运动。它们需要cost/value函数来给估计在不同情况下的每一种动作。其局限性在于计算代价是动作数的指数级的因此可扩展性不是很好。
2. 根据Clavet2016年的论文和Lee等人2010年的论文，在样本中进行k近邻搜索推动运动是可扩展性方面的限制因素。Levine等人与2012年通过在潜在空间中使用GPLVM进行强化学习的方式解决了这个问题，但该方法需要将动作分类，在每一个类中进行搜索。
3. Peng等人在2016年将强化学习应用于基于物理的动画控制空间，以处理高维状态空间。但该系统只在简单的2D环境中测试。

**1.2 形状匹配方法**是对环境进行集合分析，以使姿态或动作适应新的几何环境。

1. Lee等人于2006年进行刚性形状匹配，以适应接触丰富的运动，如坐在椅子上或躺在不同的几何形状。Grabner等人于2011年进行了强力搜索，以发现场景几何中角色可以进行特定动作的位置。古普塔等人于2011年制作了一个以各种姿势占据角色的体积，并将其放入由照片构建的虚拟曼哈顿世界。Kim等人于2014年提出利用物体的各种几何特征来使角色姿势适合不同的几何形状。Kang等人于2014年分析了人体的开放体积和身体舒适度，以预测角色在每种姿势下的静态位置。Savva等人于2016年使用微软Kinect捕捉人类与对象的交互，并生成可用于合成新场景的统计模型。然而上述这些方法只能处理静态姿势。
2. Kapadia等人于2016年估计了动态运动过程中身体与环境之间的接触，并利用这些接触将人体运动融入虚拟环境中。这种方法需要对图形作预先深入分析，不允许在角色第一次面对的新环境中进行实时交互。

### 实现将用户参数映射到潜在变量中

事实上人们更喜欢将场景参数如视点和光照条件映射到潜在变量中，这样用户就可以在合成过程中控制它们。然而Kulkarni等人于2015年提出了一种方法，将视点和人脸图像的光照条件映射到可变自动编码器的隐藏单元中；Memisavic于2013年提出了一种乘法网络，直接将潜在变量（视点）参数化为神经网络的权重，这样当潜在参数对整体输出有全局影响时，这种网络非常有效。这些方法可以被用在动作预测中并采用相位作为所有运动类型的公共参数。

### 实现角色与环境动态交互的技术

**1.1 基于运动学的动作序列合成**

**基于模板的方法**将经过剪辑的运动片段插入场景中，并依据场景进行适应性调节。这些方法易于实现，但无法为大规模动画生成连续的运动数据。

1. Kang Hoon Lee等人于2006年提出了使用积木块作为“动作补丁”，构建大面积的虚拟环境，引导角色寻找达到目标位置的方法。积木块被赋予动作数据，包含了角色所被允许进行交互的动作集合。动作补丁模型实现了在较为复杂的环境中生成角色的动作。
2. Shailen Agrawal等人于2016年提出了一种目标驱动的运动模型，该法将人物角色的几种不同类型的脚步作为模板，通过调用和优化角色的脚步计划，并以此为基础生成人物角色全身的运动。该法实现了人物角色与环境之间更密切的交互。

**基于内核的方法**解决了基于模板的方法留下的问题。

1. Tomohiko Mukai等人为了解决地质统计学的相关问题，提出了将插入的动作片段视为参数空间内的数据预测的方法。
2. Jack M. Wang等人于2008年提出了高斯过程的动力学模型(GPDMs)，并将其应用于通过高维运动捕捉数据学习人类角色的姿势和动作。该类模型包含与动力学相关的低维隐式空间，以及从隐式空间到显式空间的映射。

**1.2 通过搜索的运动合成**

1. Min Gyu Choi等人于2003年提出了环境中的概率路线图，并且使用动捕数据和概率路线图生成二足动物角色的动作。这套方案以概率路径规划和多层次位移映射为基础，包括路线图构建、路线图搜索和运动合成三个部分。
2. Wan-Yen Lo和Matthias Zwicker 于2003年将强化学习应用于引导人物角色穿过门，于2012年实现引导人物角色绕开障碍物到达目的地。
3. Safonova和Hodgins于2007年引入A*搜索算法，用于混合动作插值的权重从而产生一个新的运动。此模型相当于一个参数化的图结构。Jianyuan Min等人使用最大后验估计(MAP)优化了动作权重的混合过程。

**1.3 通过局部优化或随机优化合成运动**。Igor Mordatch等人以一种局部优化策略——接触不变的优化方法为内核，提出了一种动作合成框架。Wenping Zhao等人使用一种随机优化策略——微粒群优化算法生成人物抓取的动作。

### 应用于合成密切交互的深度学习技术

**2.1 深度监督学习技术**

1. Katerina Fragkiadaki等人在2015年将长短期记忆神经网络( Long Short Term Memory Networks, LSTMs)应用于角色移动的动画模拟；Zimo Li、Ruben Villegas等人的团队将该技术应用于更为复杂的人物动作的刻画。
2. Zimo Li等人于2017年通过自适应的递归神经网络(auto-conditioned Recurrent Neural Network, RNN)的Teacher Forcing训练机制，改善了LSTMs随着错误的积累模拟精确度逐渐下降的问题。
3. Shaojie Bai等人于2018年指出使用简单的卷积神经网络结构进行模拟的效果优于RNN和LSTMs。
4. Daniel Holden等人于2016年将时间卷积应用于这一领域的研究，并于2017年提出相位函数神经网络(PFNN)，用以进行人物角色运动的生成。
5. Robert A. Jacobs在1991年提出的多专家模型(the mixture of experts)是一种监督学习模型。以此为基础，He Zhang等人于2018年提出模式自适应神经网络(mode-adaptive neural network, MANN)，用以模拟四足动物的运动。该模型由预测神经网络和一个门网络组成。

**2.2 深度强化学习技术**

1. 深度强化学习被广泛应用于人物动作的模拟。Xue Bin Peng等人于2018年前后引入参考数据(reference data)和视频数据进行训练，弥补了由单一的数据反馈带来的不足。
2. Wenhao Yu等人于2018年提出了一种训练对称和节能的运动模式的方法。通过为损失函数引入不对称的惩罚项，以及使用额外的辅助学习(locomotion curriculum learning)，生成了更符合人类认知的行走动作。


## 4 应用和展望

